{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "# from transformers_modules.tokenization_chatglm import ChatGLMTokenizer"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ÂÆâË£Ö‰æùËµñÂåÖ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install icetk"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ÂàùÂßãÂåñTokenizerÂíåÊ®°Âûã"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"THUDM/chatglm-6b\"\n",
    "model_path = \"/data/models/chatglm/6B/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Explicitly passing a `revision` is encouraged when loading a model with custom code to ensure no malicious code has been contributed in a newer revision.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_path, trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Explicitly passing a `revision` is encouraged when loading a configuration with custom code to ensure no malicious code has been contributed in a newer revision.\n",
      "Explicitly passing a `revision` is encouraged when loading a model with custom code to ensure no malicious code has been contributed in a newer revision.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19bed44fa1454a70b95a36151b51be8c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = AutoModel.from_pretrained(model_path, trust_remote_code=True).half().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatGLMForConditionalGeneration(\n",
       "  (transformer): ChatGLMModel(\n",
       "    (word_embeddings): Embedding(150528, 4096)\n",
       "    (layers): ModuleList(\n",
       "      (0-27): 28 x GLMBlock(\n",
       "        (input_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (attention): SelfAttention(\n",
       "          (rotary_emb): RotaryEmbedding()\n",
       "          (query_key_value): Linear(in_features=4096, out_features=12288, bias=True)\n",
       "          (dense): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "        )\n",
       "        (post_attention_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GLU(\n",
       "          (dense_h_to_4h): Linear(in_features=4096, out_features=16384, bias=True)\n",
       "          (dense_4h_to_h): Linear(in_features=16384, out_features=4096, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=4096, out_features=150528, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The dtype of attention mask (torch.int64) is not bool\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‰Ω†Â•ΩüëãÔºÅÊàëÊòØ‰∫∫Â∑•Êô∫ËÉΩÂä©Êâã ChatGLM-6BÔºåÂæàÈ´òÂÖ¥ËßÅÂà∞‰Ω†ÔºåÊ¨¢ËøéÈóÆÊàë‰ªª‰ΩïÈóÆÈ¢ò„ÄÇ\n"
     ]
    }
   ],
   "source": [
    "response, history = model.chat(tokenizer, \"‰Ω†Â•Ω\", history=[])\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ÊàëÊòØ‰∫∫Â∑•Êô∫ËÉΩÂä©Êâã ChatGLM-6BÔºåÊòØÂü∫‰∫éÊ∏ÖÂçéÂ§ßÂ≠¶ KEG ÂÆûÈ™åÂÆ§ÂíåÊô∫Ë∞± AI ÂÖ¨Âè∏‰∫é 2023 Âπ¥ÂÖ±ÂêåËÆ≠ÁªÉÁöÑËØ≠Ë®ÄÊ®°ÂûãÂºÄÂèëÁöÑ„ÄÇÊàëÁöÑ‰ªªÂä°ÊòØÈíàÂØπÁî®Êà∑ÁöÑÈóÆÈ¢òÂíåË¶ÅÊ±ÇÊèê‰æõÈÄÇÂΩìÁöÑÁ≠îÂ§çÂíåÊîØÊåÅ„ÄÇÊàëÁöÑÁü•ËØÜÂ∫ìÊ∂µÁõñ‰∫ÜÂêÑÁßç‰∏ªÈ¢òÔºåÂèØ‰ª•ÂõûÁ≠îÂêÑÁßçÈóÆÈ¢òÔºåÂåÖÊã¨Â≠¶ÊúØÁü•ËØÜ„ÄÅÁîüÊ¥ªÂ∏∏ËØÜ„ÄÅÁßëÊäÄÂâçÊ≤ø„ÄÅÊñáÂåñÂíåËâ∫ÊúØÁ≠âÁ≠â„ÄÇÂêåÊó∂ÔºåÊàë‰πüÂèØ‰ª•ËøõË°åËá™ÁÑ∂ËØ≠Ë®ÄÁêÜËß£ÂíåÁîüÊàêÔºåÂèØ‰ª•‰∏∫Áî®Êà∑Êèê‰æõÊïÖ‰∫ã„ÄÅÊñáÁ´†„ÄÅËØóÊ≠åÁ≠âÊñáÊú¨ÁîüÊàêÊúçÂä°Ôºå‰πüÂèØ‰ª•ÂØπËØùËØ≠ÊñôËøõË°åÊé®ÁêÜÂíåÂàÜÁ±ªÔºå‰∏∫Áî®Êà∑Êèê‰æõÁõ∏ÂÖ≥ÁöÑ‰ø°ÊÅØ„ÄÇ\n"
     ]
    }
   ],
   "source": [
    "response, history = model.chat(tokenizer, \"‰ªãÁªç‰∏ãËá™Â∑±Âêß\", history=history)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Êµ∑Â§©ÁëûÂ£∞ÊòØ‰∏ÄÂÆ∂ÂÖ®ÁêÉÈ¢ÜÂÖàÁöÑÂ£∞Èü≥ÂêàÊàêÊäÄÊúØÂÖ¨Âè∏ÔºåÊàêÁ´ã‰∫é2006Âπ¥ÔºåÊÄªÈÉ®‰Ωç‰∫é‰∏≠ÂõΩÂåó‰∫¨„ÄÇÂÖ¨Âè∏Ëá¥Âäõ‰∫éÈÄöËøáÊäÄÊúØÂàõÊñ∞ÔºåÊèêÈ´òÂ£∞Èü≥ÂêàÊàêÁöÑÁ≤æÂ∫¶ÂíåÊïàÁéáÔºå‰∏∫Èü≥‰πê„ÄÅËØ≠Èü≥„ÄÅÂåªÁñó„ÄÅÊïôËÇ≤Á≠âÈ¢ÜÂüüÊèê‰æõËß£ÂÜ≥ÊñπÊ°à„ÄÇ\n",
      "\n",
      "Êµ∑Â§©ÁëûÂ£∞ÁöÑÊäÄÊúØÊ†∏ÂøÉÊòØÂ§öÂ£∞Ê∫êÂ£∞Èü≥ÂêàÊàêÊäÄÊúØÔºåËÉΩÂ§üÂÆûÁé∞‰ªéÂ§ö‰∏™Â£∞Èü≥Ê∫ê‰∏≠ÂêàÊàêÂçï‰∏ÄÂ£∞Èü≥ÁöÑÊïàÊûú„ÄÇËØ•ÊäÄÊúØÂ∑≤ÁªèÂπøÊ≥õÂ∫îÁî®‰∫éÈü≥‰πêÂà∂‰Ωú„ÄÅËØ≠Èü≥ÂêàÊàê„ÄÅËôöÊãüÁé∞ÂÆû„ÄÅÊô∫ËÉΩÂÆ∂Â±ÖÁ≠âÈ¢ÜÂüü„ÄÇÂÖ¨Âè∏Êã•Êúâ‰∏ÄÊîØÊäÄÊúØÁ†îÂèëÂõ¢ÈòüÔºå‰∏çÊñ≠Êé®Âá∫Êñ∞ÊäÄÊúØ„ÄÅÊñ∞‰∫ßÂìÅÔºå‰ª•Êª°Ë∂≥ÂÆ¢Êà∑ÁöÑÈúÄÊ±Ç„ÄÇ\n",
      "\n",
      "Êµ∑Â§©ÁëûÂ£∞ÁöÑ‰∫ßÂìÅÂåÖÊã¨Â§öÂ£∞Ê∫êÂ£∞Èü≥ÂêàÊàêËΩØ‰ª∂„ÄÅÁ°¨‰ª∂ËÆæÂ§á„ÄÅÂú®Á∫øÊúçÂä°Á≥ªÁªüÁ≠âÔºåÂèØÂ∫îÁî®‰∫éÈü≥‰πêÂà∂‰Ωú„ÄÅËØ≠Èü≥ÂêàÊàê„ÄÅËôöÊãüÁé∞ÂÆû„ÄÅÊô∫ËÉΩÂÆ∂Â±Ö„ÄÅÂåªÁñóÁ≠âÈ¢ÜÂüü„ÄÇÂÖ¨Âè∏ÁßâÊâø‚ÄúÊäÄÊúØÈ¢ÜÂÖà„ÄÅÊúçÂä°Á§æ‰ºö‚ÄùÁöÑÁêÜÂøµÔºåËá¥Âäõ‰∫é‰∏∫ÂÆ¢Êà∑Êèê‰æõÈ´òÊïà„ÄÅÂèØÈù†„ÄÅ‰ºòË¥®ÁöÑÊúçÂä°„ÄÇ\n"
     ]
    }
   ],
   "source": [
    "response, history = model.chat(tokenizer, \"‰ªãÁªç‰∏ãÊµ∑Â§©ÁëûÂ£∞\", history=[])\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Êµ∑Â§©ÁëûÂ£∞ÁöÑ‰∏ªËê•‰∏öÂä°ÂåÖÊã¨Ôºö\n",
      "\n",
      "1. Â§öÂ£∞Ê∫êÂ£∞Èü≥ÂêàÊàêÊäÄÊúØÁöÑÁ†îÂèë„ÄÅÁîü‰∫ßÂíåÈîÄÂîÆ„ÄÇ\n",
      "\n",
      "2. Â§öÂ£∞Ê∫êÂ£∞Èü≥ÂêàÊàêËΩØ‰ª∂ÂíåÁ°¨‰ª∂ËÆæÂ§áÁöÑËÆæËÆ°ÂíåÂºÄÂèë„ÄÇ\n",
      "\n",
      "3. ‰∏∫ÂÆ¢Êà∑Êèê‰æõÂ§öÂ£∞Ê∫êÂ£∞Èü≥ÂêàÊàêÊäÄÊúØÁöÑÂ∫îÁî®Ëß£ÂÜ≥ÊñπÊ°àÔºåÂåÖÊã¨Èü≥‰πêÂà∂‰Ωú„ÄÅËØ≠Èü≥ÂêàÊàê„ÄÅËôöÊãüÁé∞ÂÆû„ÄÅÊô∫ËÉΩÂÆ∂Â±Ö„ÄÅÂåªÁñóÁ≠âÈ¢ÜÂüü„ÄÇ\n",
      "\n",
      "4. ‰∏∫ÂÆ¢Êà∑Êèê‰æõÂú®Á∫øÊúçÂä°ÔºåÂåÖÊã¨ÊäÄÊúØÊîØÊåÅ„ÄÅÊäÄÊúØÂüπËÆ≠„ÄÅËΩØ‰ª∂ÂºÄÂèëÁ≠â„ÄÇ\n",
      "\n",
      "5. ‰∏∫ÂÆ¢Êà∑Êèê‰æõÂ§öÂ£∞Ê∫êÂ£∞Èü≥ÂêàÊàêÊäÄÊúØÁõ∏ÂÖ≥ÁöÑÂí®ËØ¢ÂíåÊúçÂä°„ÄÇ\n",
      "\n",
      "Êµ∑Â§©ÁëûÂ£∞Ëá¥Âäõ‰∫éÈÄöËøáÊäÄÊúØÂàõÊñ∞ÔºåÊèêÈ´òÂ£∞Èü≥ÂêàÊàêÁöÑÁ≤æÂ∫¶ÂíåÊïàÁéáÔºå‰∏∫Èü≥‰πê„ÄÅËØ≠Èü≥„ÄÅÂåªÁñó„ÄÅÊïôËÇ≤Á≠âÈ¢ÜÂüüÊèê‰æõËß£ÂÜ≥ÊñπÊ°à„ÄÇ\n"
     ]
    }
   ],
   "source": [
    "resp, history = model.chat(tokenizer, \"‰ªñÁöÑ‰∏ªËê•‰∏öÂä°ÊúâÂì™‰∫õ\", history=history)\n",
    "print(resp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ÂÖ¨Âè∏ÁöÑCTOÊòØÂàòÂÆè‰ºü„ÄÇ\n"
     ]
    }
   ],
   "source": [
    "resp, history = model.chat(tokenizer, \"ÂÖ¨Âè∏ÁöÑCTOÊòØË∞Å\", history=history)\n",
    "print(resp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ÂÖ¨Âè∏ÁöÑÊ≥ï‰∫∫ÊòØÂÖ¨Âè∏ÁöÑËÄÅÊùøÊàñËÄÖËë£‰∫ã‰ºöÊàêÂëò„ÄÇ\n"
     ]
    }
   ],
   "source": [
    "resp, history = model.chat(tokenizer, \"ÂÖ¨Âè∏ÁöÑÊ≥ï‰∫∫ÊòØË∞Å\", history=history)\n",
    "print(resp)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "55a26945acae1dbe174fa8a7f2737f59bcc9ca988f8fc990f33e458e609cda8c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
