{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from llama import Transformer, ModelArgs\n",
    "from llama_tokenizer import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_path = \"/data/models/LLaMA/7B/tokenizer.model\"\n",
    "tokenizer = Tokenizer(tokenizer_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sentence = \"海天瑞声\"\n",
    "# tokenizer.decode(tokenizer.encode(sentence, False, False)) == sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"dim\": 4096,\n",
    "    \"n_layers\": 32,\n",
    "    \"n_heads\": 32,\n",
    "    \"vocab_size\": 32000,\n",
    "    \"multiple_of\": 256,\n",
    "    \"norm_eps\": 1e-06,\n",
    "}\n",
    "model_args = ModelArgs(**params)\n",
    "model = Transformer(model_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_IncompatibleKeys(missing_keys=[], unexpected_keys=['layers.0.attention.inner_attention.rope.freqs', 'layers.1.attention.inner_attention.rope.freqs', 'layers.2.attention.inner_attention.rope.freqs', 'layers.3.attention.inner_attention.rope.freqs', 'layers.4.attention.inner_attention.rope.freqs', 'layers.5.attention.inner_attention.rope.freqs', 'layers.6.attention.inner_attention.rope.freqs', 'layers.7.attention.inner_attention.rope.freqs', 'layers.8.attention.inner_attention.rope.freqs', 'layers.9.attention.inner_attention.rope.freqs', 'layers.10.attention.inner_attention.rope.freqs', 'layers.11.attention.inner_attention.rope.freqs', 'layers.12.attention.inner_attention.rope.freqs', 'layers.13.attention.inner_attention.rope.freqs', 'layers.14.attention.inner_attention.rope.freqs', 'layers.15.attention.inner_attention.rope.freqs', 'layers.16.attention.inner_attention.rope.freqs', 'layers.17.attention.inner_attention.rope.freqs', 'layers.18.attention.inner_attention.rope.freqs', 'layers.19.attention.inner_attention.rope.freqs', 'layers.20.attention.inner_attention.rope.freqs', 'layers.21.attention.inner_attention.rope.freqs', 'layers.22.attention.inner_attention.rope.freqs', 'layers.23.attention.inner_attention.rope.freqs', 'layers.24.attention.inner_attention.rope.freqs', 'layers.25.attention.inner_attention.rope.freqs', 'layers.26.attention.inner_attention.rope.freqs', 'layers.27.attention.inner_attention.rope.freqs', 'layers.28.attention.inner_attention.rope.freqs', 'layers.29.attention.inner_attention.rope.freqs', 'layers.30.attention.inner_attention.rope.freqs', 'layers.31.attention.inner_attention.rope.freqs'])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_path = \"/data/models/LLaMA/7B/consolidated.00.pth\"\n",
    "state_dict = torch.load(model_path)\n",
    "model.load_state_dict(state_dict=state_dict, strict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 4103, 24784, 31222,   234,   190,   159,   233,   161,   185, 31901]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_list = tokenizer.encode(\"Transformer网络架构\", bos=False, eos=False)\n",
    "tokens = torch.tensor(token_list).unsqueeze(0)\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 10, 4096])\n"
     ]
    }
   ],
   "source": [
    "output, hidden = model(tokens, 0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "55a26945acae1dbe174fa8a7f2737f59bcc9ca988f8fc990f33e458e609cda8c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
